{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Ambition",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serhatataman/ProjectAmbitionColab/blob/main/Project_Ambition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muy2Y5jKDipP"
      },
      "source": [
        "# Project Ambition\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the NVIDIA driver's availability\n",
        "Note: if this step gives `NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running` error, select GPU as hardware accelerator in `Edit > Notebook settings`."
      ],
      "metadata": {
        "id": "lPBybcggXMFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGZ8hikAV80H",
        "outputId": "ef8e8337-7b64-4a4f-9547-d0aa7e4ec1ce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  1 20:23:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "/bin/bash: line 0: kill: -pid_number: arguments must be process or job IDs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount to the drive to the following location.\n",
        "\n",
        "```\n",
        "/content/drive/MyDrive/data\n",
        "```\n",
        "\n",
        "Use ```ls``` command to establish the exact path for your images."
      ],
      "metadata": {
        "id": "dx8alQk_XBWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Using Google CoLab\")\n",
        "except:\n",
        "    print(\"Not using Google CoLab\")\n",
        "    COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeMVNvOyXFQW",
        "outputId": "f173b11e-846c-490b-8e0d-e888dc319590"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using Google CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe_S5N3xZd6B",
        "outputId": "8c67bec4-639a-4899-965c-ee63d20d5df2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'\t\t\t  'Master Application Docs.'\n",
            "'Copy of [#1 Sharing Session] TSO.docx'    Personal\n",
            "'Copy of [#4 Re-Entry Session] TSO.docx'   ProjectAmbition\n",
            "'CS:GO config'\t\t\t\t  'Reflection groups guideline.gdoc'\n",
            " CV\t\t\t\t\t   UDI\n",
            "'Graduation Thesis'\t\t\t   Wallpapers\n",
            " ielts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGKA5Q7uEbR2"
      },
      "source": [
        "\n",
        "### Import NVIDIA stylegan3\n",
        "\n",
        "If the repo is already installed, it will skip the installation process and change into the repo’s directory. If not, it will install all the files necessary.\n",
        "Also, create `downloads` and `datasets` folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b54cee4-7c17-496e-dbca-c5a5954281d0"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/ProjectAmbition\"):\n",
        "    %cd \"/content/drive/MyDrive/ProjectAmbition\"\n",
        "else:\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir ProjectAmbition\n",
        "    %cd ProjectAmbition\n",
        "    !git clone https://github.com/NVlabs/stylegan3\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir raw_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ProjectAmbition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/ProjectAmbition/stylegan3\"\n",
        "!git config --global user.name \"serhatataman\"\n",
        "!git config --global user.email \"serhatataman13@hotmail.com\"\n",
        "!git fetch origin\n",
        "!git checkout origin/main -- train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRItln1dee3m",
        "outputId": "97b5990d-ecf4-4270-c935-3d779e4628e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ProjectAmbition/stylegan3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SCfdoIkYfbV",
        "outputId": "84060310-07f7-446f-c46b-33e9ca213119"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Checking if directories/files exist"
      ],
      "metadata": {
        "id": "KLRvzXGrfF2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/stylegan3/dataset_tool.py\"):\n",
        "  raise FileNotFoundError(\"dataset_tool.py file does not exist!\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/raw_data\"):\n",
        "  raise FileNotFoundError(\"raw_data folder does not exist!\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/dataset\"):\n",
        "  print(\"dataset folder does not exist! creating the folder...\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/ProjectAmbition/dataset\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/output\"):\n",
        "  print(\"output folder does not exist! creating the folder...\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/ProjectAmbition/output\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GK0kPaGflpI",
        "outputId": "7fc1bddd-d63a-477e-aace-73dbabaae484"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset folder does not exist! creating the folder...\n",
            "output folder does not exist! creating the folder...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleanup images"
      ],
      "metadata": {
        "id": "GOqy7Uvel427"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See what dataset_tool.py can do"
      ],
      "metadata": {
        "id": "KsBQgoD3LX-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/dataset_tool.py --help\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "gXIAsscwLa5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove frames\n",
        "\n",
        "Remove frames if there are any. This process overrides the picture with frames removed."
      ],
      "metadata": {
        "id": "FPXQ-z-SmXdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.spatial import distance\n",
        "\n",
        "# This python script removes pictures' frames if there are any\n",
        "\n",
        "from_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "to_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "\n",
        "\n",
        "def find_left():\n",
        "    left = 0\n",
        "    for i in range(0, w_pad):\n",
        "        r_stdev = np.std(np_img[h_pad:-h_pad, i:i + 1, 0:1])\n",
        "        g_stdev = np.std(np_img[h_pad:-h_pad, i:i + 1, 1:2])\n",
        "        b_stdev = np.std(np_img[h_pad:-h_pad, i:i + 1, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[h_pad:-h_pad, i:i + 1, 0:1])\n",
        "        g_med = np.median(np_img[h_pad:-h_pad, i:i + 1, 1:2])\n",
        "        b_med = np.median(np_img[h_pad:-h_pad, i:i + 1, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        left = left + 1\n",
        "    return left\n",
        "\n",
        "\n",
        "def find_top():\n",
        "    top = 0\n",
        "    for i in range(0, h_pad):\n",
        "        r_stdev = np.std(np_img[i:i + 1, w_pad:-w_pad, 0:1])\n",
        "        g_stdev = np.std(np_img[i:i + 1, w_pad:-w_pad, 1:2])\n",
        "        b_stdev = np.std(np_img[i:i + 1, w_pad:-w_pad, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[i:i + 1, w_pad:-w_pad, 0:1])\n",
        "        g_med = np.median(np_img[i:i + 1, w_pad:-w_pad, 1:2])\n",
        "        b_med = np.median(np_img[i:i + 1, w_pad:-w_pad, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        top = top + 1\n",
        "    return top\n",
        "\n",
        "\n",
        "def find_right(right):\n",
        "    right = w\n",
        "    for i in range(0, w_pad):\n",
        "        r_stdev = np.std(np_img[h_pad:-h_pad, w - i - 1:w - i, 0:1])\n",
        "        g_stdev = np.std(np_img[h_pad:-h_pad, w - i - 1:w - i, 1:2])\n",
        "        b_stdev = np.std(np_img[h_pad:-h_pad, w - i - 1:w - i, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[h_pad:-h_pad, w - i - 1:w - i, 0:1])\n",
        "        g_med = np.median(np_img[h_pad:-h_pad, w - i - 1:w - i, 1:2])\n",
        "        b_med = np.median(np_img[h_pad:-h_pad, w - i - 1:w - i, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        right = right - 1\n",
        "    return right\n",
        "\n",
        "\n",
        "def find_bottom(bottom):\n",
        "    for i in range(0, h_pad):\n",
        "        r_stdev = np.std(np_img[h - i - 1:h - i, w_pad:-w_pad, 0:1])\n",
        "        g_stdev = np.std(np_img[h - i - 1:h - i, w_pad:-w_pad, 1:2])\n",
        "        b_stdev = np.std(np_img[h - i - 1:h - i, w_pad:-w_pad, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[h - i - 1:h - i, w_pad:-w_pad, 0:1])\n",
        "        g_med = np.median(np_img[h - i - 1:h - i, w_pad:-w_pad, 1:2])\n",
        "        b_med = np.median(np_img[h - i - 1:h - i, w_pad:-w_pad, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        bottom = bottom - 1\n",
        "    return bottom\n",
        "\n",
        "\n",
        "for file in os.listdir(from_path):\n",
        "    path = os.path.join(from_path, file)\n",
        "    img = Image.open(path)\n",
        "    file_name, file_extension = os.path.splitext(path)\n",
        "    print('Removing frames for image:', file_name + file_extension)\n",
        "\n",
        "    np_img = np.asarray(img)\n",
        "    # print(\"shape = \" + str(np_img.shape))\n",
        "\n",
        "    thresh1 = 15000\n",
        "    thresh2 = 30\n",
        "    w = img.width\n",
        "    h = img.height\n",
        "    pad = 30\n",
        "    w_pad = w // pad\n",
        "    h_pad = h // pad\n",
        "\n",
        "    r_global_med = np.median(np_img[h_pad:-h_pad, w_pad:-w_pad, 0:1])\n",
        "    g_global_med = np.median(np_img[h_pad:-h_pad, w_pad:-w_pad, 1:2])\n",
        "    b_global_med = np.median(np_img[h_pad:-h_pad, w_pad:-w_pad, 2:3])\n",
        "\n",
        "    left = find_left()\n",
        "    top = find_top()\n",
        "    right = find_right(w)\n",
        "    bottom = find_bottom(h)\n",
        "\n",
        "    # print(\"left = \" + str(left) + \", top = \" + str(top) +\n",
        "      #    \", right = \" + str(right) + \", bottom = \" + str(bottom) + \"\\n\")\n",
        "\n",
        "    # img.save(to_path + file)  # save the original\n",
        "    cropped_img = img.crop((left, top, right, bottom))\n",
        "    cropped_img.save(file_name + file_extension)  # and the cropped version\n"
      ],
      "metadata": {
        "id": "SD-E7AK-mbW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ea4e87-a1eb-4ef4-983e-549ab7175cdb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing frames for image: /content/drive/MyDrive/ProjectAmbition/raw_data/peasant-and-horse-1910.jpg\n",
            "Removing frames for image: /content/drive/MyDrive/ProjectAmbition/raw_data/horses.jpg\n",
            "Removing frames for image: /content/drive/MyDrive/ProjectAmbition/raw_data/spring-1907.jpg\n",
            "Removing frames for image: /content/drive/MyDrive/ProjectAmbition/raw_data/the-rise-of-green-square-and-the-woman-s-violin-1916.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resize images\n",
        "\n",
        "Resize images to 1024x1024 and override them."
      ],
      "metadata": {
        "id": "CW68PWCUqezM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_source_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "image_target_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "\n",
        "# We are using Pillow to resize all images to our desired size\n",
        "\n",
        "for filename in os.listdir(image_source_path):\n",
        "    path = os.path.join(image_source_path, filename)\n",
        "    image = Image.open(path).resize((1024, 1024), Image.ANTIALIAS)\n",
        "\n",
        "    resized_image = image.save(image_target_path + filename)\n",
        "    print(f\"{filename} image is resized...\")\n"
      ],
      "metadata": {
        "id": "fEiSVY8mqlci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82034d55-b0af-4db4-9e19-7f4c2f951c1c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peasant-and-horse-1910.jpg image is resized...\n",
            "horses.jpg image is resized...\n",
            "spring-1907.jpg image is resized...\n",
            "the-rise-of-green-square-and-the-woman-s-violin-1916.jpg image is resized...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert images\n",
        "\n",
        "Convert raw data images to dataset by using StyleGAN3's built-in dataset_tool.py"
      ],
      "metadata": {
        "id": "mSZS_v2F07l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ProjectAmbition/stylegan3/dataset_tool.py --source /content/drive/MyDrive/ProjectAmbition/raw_data/ --dest /content/drive/MyDrive/ProjectAmbition/dataset/ --resolution=1024x1024 --transform=center-crop-wide"
      ],
      "metadata": {
        "id": "nYWi_5DSfKoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ea1922-b501-4cca-faf4-920315d03c23"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4/4 [00:00<00:00,  8.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following command can be used to clear out the newly created dataset. If something goes wrong and you need to clean up your images and rerun the above command, you should delete your partially created dataset directory."
      ],
      "metadata": {
        "id": "JfUa1rMSlvTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -R /content/drive/MyDrive/ProjectAmbition/dataset/*"
      ],
      "metadata": {
        "id": "pS0JPUa0lzoJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "VIF5keq1x9MA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial training"
      ],
      "metadata": {
        "id": "Ct68q26xyA2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/train.py --help\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "txTGnCbG5V0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
        "\n",
        "# Modify these to suit your needs\n",
        "OUTPUT = \"/content/drive/MyDrive/ProjectAmbition/output\"\n",
        "DATA = \"/content/drive/MyDrive/ProjectAmbition/dataset\"\n",
        "# Snap: How often should the model generate samples and a .pkl file\n",
        "SNAP = 4\n",
        "# Mirrored: Should the images be mirrored left to right?\n",
        "MIRRORED = True\n",
        "\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/train.py --cfg=stylegan3-t --gpus=1 --batch=32 --gamma=8.2 --snap {SNAP} --outdir {OUTPUT} --data {DATA} --mirror={MIRRORED}\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "Puuif5Y7yBXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd9e274-7052-45a3-c278-537dd5e114f3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.2\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/ProjectAmbition/dataset\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 4,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 1024,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 32,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 25000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/ProjectAmbition/output/00000-stylegan3-t-dataset-gpus1-batch32-gamma8.2\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/ProjectAmbition/output/00000-stylegan3-t-dataset-gpus1-batch32-gamma8.2\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   25000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/ProjectAmbition/dataset\n",
            "Dataset size:        4 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  8\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/training/training_loop.py\", line 168, in training_loop\n",
            "    img = misc.print_module_summary(G, [z, c])\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/torch_utils/misc.py\", line 216, in print_module_summary\n",
            "    outputs = module(*inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/training/networks_stylegan3.py\", line 512, in forward\n",
            "    img = self.synthesis(ws, update_emas=update_emas, **synthesis_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/training/networks_stylegan3.py\", line 471, in forward\n",
            "    x = getattr(self, name)(x, w, **layer_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/training/networks_stylegan3.py\", line 356, in forward\n",
            "    up=self.up_factor, down=self.down_factor, padding=self.padding, gain=gain, slope=slope, clamp=self.conv_clamp)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/torch_utils/ops/filtered_lrelu.py\", line 115, in filtered_lrelu\n",
            "    return _filtered_lrelu_cuda(up=up, down=down, padding=padding, gain=gain, slope=slope, clamp=clamp, flip_filter=flip_filter).apply(x, fu, fd, b, None, 0, 0)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/torch_utils/ops/filtered_lrelu.py\", line 217, in forward\n",
            "    y, so, return_code = _plugin.filtered_lrelu(x, fu, fd, b, si, up, down, px0, px1, py0, py1, sx, sy, gain, slope, clamp, flip_filter, write_signs)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 2.16 GiB (GPU 0; 11.17 GiB total capacity; 5.59 GiB already allocated; 1.05 GiB free; 9.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resume training"
      ],
      "metadata": {
        "id": "y8MZ2hfhyB35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# Modify these to suit your needs\n",
        "OUTPUT = \"/content/drive/MyDrive/ProjectAmbition/output\"\n",
        "NETWORK = \"network-snapshot-000100.pkl\"\n",
        "RESUME = os.path.join(OUTPUT, \"00008-circuit-auto1-resumecustom\", NETWORK)\n",
        "DATA = \"/content/drive/MyDrive/ProjectAmbition/dataset\"\n",
        "# Snap: How often should the model generate samples and a .pkl file\n",
        "SNAP = 4\n",
        "# Mirrored: Should the images be mirrored left to right?\n",
        "MIRRORED = True\n",
        "# Mirrored_y: Should the images be mirrored top to bottom?\n",
        "MIRRORED_Y = True\n",
        "\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/train.py --cfg=stylegan3-t --gpus=8 --batch=32 --gamma=8.2 --snap {SNAP} --resume {RESUME} --outdir {OUTPUT} --data {DATA} --mirror={MIRRORED} --mirrory={MIRRORED_Y}\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "7fNrhw89yCVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate image"
      ],
      "metadata": {
        "id": "j6-C0KSpyDD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5KP0UWdqyD49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rgZqHe1eyEWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}