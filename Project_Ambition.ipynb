{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Ambition",
      "provenance": [],
      "collapsed_sections": [
        "FPXQ-z-SmXdE"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serhatataman/ProjectAmbitionColab/blob/main/Project_Ambition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muy2Y5jKDipP"
      },
      "source": [
        "# Project Ambition\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enable GPU"
      ],
      "metadata": {
        "id": "EH7Cfdjb4f3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The type of GPU assigned to you by Colab will greatly affect your training time. Some sample times that I achieved with Colab are given here. I've found that Colab Pro generally starts you with a V100, however, if you run scripts non-stop for 24hrs straight for a few days in a row, you will generally be throttled back to a P100.\n",
        "\n",
        "*   1024x1024 - V100 - 566 sec/tick (CoLab Pro)\n",
        "*   1024x1024 - P100 - 1819 sec/tick (CoLab Pro)\n",
        "*   1024x1024 - T4 - 2188 sec/tick (CoLab Free)\n",
        "\n",
        "\n",
        "If you use Google CoLab Pro, generally, it will not disconnect before 24 hours, even if you (but not your script) are inactive. Free CoLab WILL disconnect a perfectly good running script if you do not interact for a few hours. The following describes how to circumvent this issue.\n",
        "\n",
        "\n",
        "Note: if this step gives `NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running` error, select GPU as hardware accelerator in `Edit > Notebook settings`."
      ],
      "metadata": {
        "id": "lPBybcggXMFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGZ8hikAV80H",
        "outputId": "bd7c2e96-587d-4c4e-8990-6897bd7c17a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 11 15:35:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cb07c7-2248-4b48-e3f3-2bfca047398b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "### Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_BbYAld4kTY",
        "outputId": "1ab57b73-bccf-4e29-e9c6-fb06cd032558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.7.0\n",
            "Running on TPU  ['10.125.9.58:8470']\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.9.58:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.125.9.58:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount to the Google Drive\n",
        "```\n",
        "/content/drive/MyDrive/data\n",
        "```\n",
        "\n",
        "Use ```ls``` command to establish the exact path for your images."
      ],
      "metadata": {
        "id": "dx8alQk_XBWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Using Google CoLab\")\n",
        "except:\n",
        "    print(\"Not using Google CoLab\")\n",
        "    COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeMVNvOyXFQW",
        "outputId": "9fe7ca81-0e65-4bea-e655-254c468f52c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using Google CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe_S5N3xZd6B",
        "outputId": "83fd8b51-9c28-4a9f-a02c-69e035d56f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'\t\t\t  'Master Application Docs.'\n",
            "'Copy of [#1 Sharing Session] TSO.docx'    Personal\n",
            "'Copy of [#4 Re-Entry Session] TSO.docx'   ProjectAmbition\n",
            "'CS:GO config'\t\t\t\t  'Reflection groups guideline.gdoc'\n",
            " CV\t\t\t\t\t   tests\n",
            "'Graduation Thesis'\t\t\t   UDI\n",
            " ielts\t\t\t\t\t   Wallpapers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGKA5Q7uEbR2"
      },
      "source": [
        "\n",
        "### Import NVIDIA stylegan3\n",
        "\n",
        "If the repo is already installed, it will skip the installation process and change into the repo’s directory. If not, it will install all the files necessary.\n",
        "Also, create `downloads` and `datasets` folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b54cee4-7c17-496e-dbca-c5a5954281d0"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/ProjectAmbition\"):\n",
        "    %cd \"/content/drive/MyDrive/ProjectAmbition\"\n",
        "else:\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir ProjectAmbition\n",
        "    %cd ProjectAmbition\n",
        "    !git clone https://github.com/NVlabs/stylegan3\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir raw_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ProjectAmbition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/ProjectAmbition/stylegan3\"\n",
        "!git config --global user.name \"serhatataman\"\n",
        "!git config --global user.email \"serhatataman13@hotmail.com\"\n",
        "!git fetch origin\n",
        "!git checkout origin/main -- train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRItln1dee3m",
        "outputId": "97b5990d-ecf4-4270-c935-3d779e4628e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ProjectAmbition/stylegan3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Checking if directories/files exist"
      ],
      "metadata": {
        "id": "KLRvzXGrfF2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/stylegan3/dataset_tool.py\"):\n",
        "  raise FileNotFoundError(\"dataset_tool.py file does not exist!\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/raw_data\"):\n",
        "  raise FileNotFoundError(\"raw_data folder does not exist!\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/dataset\"):\n",
        "  print(\"dataset folder does not exist! creating the folder...\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/ProjectAmbition/dataset\")\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ProjectAmbition/output\"):\n",
        "  print(\"output folder does not exist! creating the folder...\")\n",
        "  os.mkdir(\"/content/drive/MyDrive/ProjectAmbition/output\")"
      ],
      "metadata": {
        "id": "5GK0kPaGflpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch images"
      ],
      "metadata": {
        "id": "ZW8BykZWxeCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download from webscrap of WikiArt"
      ],
      "metadata": {
        "id": "R0zxbFebhphg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/ProjectAmbition/raw_data\"\n",
        "base_url = \"https://www.wikiart.org\"\n",
        "\n",
        "# iterate through all artists by last name alphabetically\n",
        "for c in range(ord('a'), ord('z') + 1):\n",
        "    char = chr(c)\n",
        "    artist_list_url = base_url + '/en/Alphabet/' + char + '/text-list'\n",
        "\n",
        "    genre_soup = BeautifulSoup(urllib.request.urlopen(artist_list_url), \"lxml\")\n",
        "    artist_list_main = genre_soup.find(\"main\")\n",
        "    lis = artist_list_main.find_all(\"li\")\n",
        "\n",
        "    # for each list element\n",
        "    for li in lis:\n",
        "\n",
        "        # get the date range\n",
        "        for line in li.text.splitlines():\n",
        "            # if line.startswith(\",\") and \"-\" in line:\n",
        "            #     parts = line.split('-')\n",
        "            #     if len(parts) == 2:\n",
        "            #         born = int(re.sub(\"[^0-9]\", \"\", parts[0]))\n",
        "            #         died = int(re.sub(\"[^0-9]\", \"\", parts[1]))\n",
        "\n",
        "            # look for artists who may have created work that could in public domain\n",
        "            # if born > 1850 and died > 0 and (born < 1900 or died < 1950):\n",
        "\n",
        "            link = li.find(\"a\")\n",
        "            if link is None:\n",
        "                continue\n",
        "\n",
        "            artist = link.attrs[\"href\"]\n",
        "\n",
        "            # get the artist's main page\n",
        "            artist_url = base_url + artist\n",
        "            artist_soup = BeautifulSoup(urllib.request.urlopen(artist_url), \"lxml\")\n",
        "\n",
        "            # only look for artists with the word abstract on their main page\n",
        "            if \"Abstract\" in artist_soup.text or \"abstract\" in artist_soup.text or \"Avant-garde\" \\\n",
        "                    in artist_soup.text or \"avant-garde\" in artist_soup.text:\n",
        "                print('Artist: ' + artist)\n",
        "\n",
        "                # get the artist's web page for the artwork\n",
        "                url = base_url + artist + '/all-works/text-list'\n",
        "\n",
        "                try:\n",
        "                    artist_work_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
        "                except:\n",
        "                    print(\"Error retrieving artist's work list. Url was: \" + url)\n",
        "                    continue\n",
        "\n",
        "                # get the main section\n",
        "                artist_main = artist_work_soup.find(\"main\")\n",
        "                image_count = 0\n",
        "                artist_name = artist.split(\"/\")[2]\n",
        "\n",
        "                # get the list of artwork\n",
        "                lis = artist_main.find_all(\"li\")\n",
        "\n",
        "                # for each list element\n",
        "                for li in lis:\n",
        "                    link = li.find(\"a\")\n",
        "\n",
        "                    if link != None:\n",
        "                        painting = link.attrs[\"href\"]\n",
        "\n",
        "                        # get the painting\n",
        "                        url = base_url + painting\n",
        "                        # print('Painting base url: ' + url)\n",
        "\n",
        "                        try:\n",
        "                            painting_soup = BeautifulSoup(urllib.request.urlopen(url), \"lxml\")\n",
        "\n",
        "                        except:\n",
        "                            print(\"error retrieving page\")\n",
        "                            continue\n",
        "\n",
        "                        # check the copyright\n",
        "                        if \"Public domain\" in painting_soup.text:\n",
        "\n",
        "                            # check the genre\n",
        "                            genre = painting_soup.find(\"span\", {\"itemprop\": \"genre\"})\n",
        "                            if genre != None and genre.text == \"abstract\":\n",
        "\n",
        "                                # get the url\n",
        "                                og_image = painting_soup.find(\"meta\", {\"property\": \"og:image\"})\n",
        "                                image_url = og_image[\"content\"].split(\"!\")[0]  # ignore the !Large.jpg at the end\n",
        "\n",
        "                                save_path = file_path + \"/\" + artist_name + \"_\" + str(image_count) + \".jpg\"\n",
        "\n",
        "                                # download the file\n",
        "                                try:\n",
        "                                    print(f\"Downloading {image_url} to {save_path}\")\n",
        "                                    time.sleep(0.2)  # try not to get a 403\n",
        "                                    urllib.request.urlretrieve(image_url, save_path)\n",
        "                                    image_count = image_count + 1\n",
        "                                except Exception as e:\n",
        "                                    print(\"Failed downloading \" + image_url, e)\n"
      ],
      "metadata": {
        "id": "9h9-uiDZxghm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download zip of art pieces"
      ],
      "metadata": {
        "id": "08p5Qj94vyad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "zip_file_url = 'http://web.fsktm.um.edu.my/~cschan/source/ICIP2017/wikiart.zip'\n",
        "\n",
        "# NOTE the stream=True parameter below\n",
        "with requests.get(zip_file_url, stream=True) as response:\n",
        "  response.raise_for_status()\n",
        "  handle = open('/content/drive/MyDrive/ProjectAmbition/downloads/data.zip', \"wb\")\n",
        "  for chunk in response.iter_content(chunk_size=8192): \n",
        "      # If you have chunk encoded response uncomment if\n",
        "      # and set chunk_size parameter to None.\n",
        "      #if chunk: \n",
        "      handle.write(chunk)\n",
        "\n",
        "  handle.close()\n",
        "\n",
        "# Note that the number of bytes returned using iter_content is not exactly the chunk_size;\n",
        "# it's expected to be a random number that is often far bigger, and is expected to be different in every iteration.\n",
        "# See body-content-workflow and Response.iter_content for further reference.\n",
        "\n",
        "print('Download completed...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM4CRE7Lhzc8",
        "outputId": "ff2c3d1d-a667-4f3b-ebdc-665bbfd65332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip downloaded files"
      ],
      "metadata": {
        "id": "LSrDe3eOyIuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_filename = \"/content/drive/MyDrive/ProjectAmbition/downloads/data.zip\"\n",
        "directory_to_extract_to = \"/content/drive/MyDrive/ProjectAmbition/downloads/\"\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
        "    for name in zip_ref.namelist():\n",
        "        try:\n",
        "            zip_ref.extract(name, directory_to_extract_to)\n",
        "        except (Exception, zipfile.BadZipFile) as e:\n",
        "            print(\"A file is corrupted. Filename: \" + str(name))\n",
        "            print(e)\n",
        "\n",
        "print(\"Unzip successful...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9MLyL8byHmE",
        "outputId": "7b250911-4402-4e4c-fbb2-ed9d161f7784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A file is corrupted. Filename: wikiart/Baroque/rembrandt_woman-standing-with-raised-hands.jpg\n",
            "Bad CRC-32 for file 'wikiart/Baroque/rembrandt_woman-standing-with-raised-hands.jpg'\n",
            "A file is corrupted. Filename: wikiart/Post_Impressionism/vincent-van-gogh_l-arlesienne-portrait-of-madame-ginoux-1890.jpg\n",
            "Error -3 while decompressing data: invalid block type\n",
            "Unzip successful...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move Images\n",
        "\n",
        "Move images from different sources to a single file"
      ],
      "metadata": {
        "id": "xK9pkfdE25FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "target_dir = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "\n",
        "modern = '/content/drive/MyDrive/ProjectAmbition/downloads/wikiart/Art_Nouveau_Modern/'\n",
        "abstract = '/content/drive/MyDrive/ProjectAmbition/downloads/wikiart/Abstract_Expressionism/'\n",
        "fauvism = '/content/drive/MyDrive/ProjectAmbition/downloads/wikiart/Fauvism/'\n",
        "impressionism = '/content/drive/MyDrive/ProjectAmbition/downloads/wikiart/Impressionism/'\n",
        "\n",
        "print('Art Nouveau has: ' + str(len(os.listdir(modern))))\n",
        "print('Abstract has: ' + str(len(os.listdir(abstract))))\n",
        "print('Fauvism has: ' + str(len(os.listdir(fauvism))))\n",
        "print('Impressionism has: ' + str(len(os.listdir(impressionism))))\n",
        "\n",
        "# Exception is handled in case there are duplicated images\n",
        "\n",
        "print(\"Moving Art Nouveau files...\")    \n",
        "file_names = os.listdir(modern)\n",
        "for file_name in file_names:\n",
        "  try:\n",
        "    shutil.move(os.path.join(modern, file_name), target_dir)\n",
        "  except Exception as e: \n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "print(\"Moving Abstract files...\")    \n",
        "file_names = os.listdir(abstract)\n",
        "for file_name in file_names:\n",
        "  try:\n",
        "    shutil.move(os.path.join(abstract, file_name), target_dir)\n",
        "  except Exception as e: \n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "print(\"Moving Fauvism files...\")    \n",
        "file_names = os.listdir(fauvism)\n",
        "for file_name in file_names:\n",
        "  try:\n",
        "    shutil.move(os.path.join(fauvism, file_name), target_dir)\n",
        "  except Exception as e: \n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "print(\"Moving Impressionism files...\")    \n",
        "file_names = os.listdir(impressionism)\n",
        "for file_name in file_names:\n",
        "  try:\n",
        "    shutil.move(os.path.join(impressionism, file_name), target_dir)\n",
        "  except Exception as e: \n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "print(\"Moving files is successful!\")\n"
      ],
      "metadata": {
        "id": "yxqBBFKn24YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dir = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "\n",
        "print('Target direcotry has: ' + str(len(os.listdir(target_dir))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C15JNv5mVmW-",
        "outputId": "44499f95-1556-4e59-964c-36f106a7b4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target direcotry has: 20903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleanup images"
      ],
      "metadata": {
        "id": "GOqy7Uvel427"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See what dataset_tool.py can do"
      ],
      "metadata": {
        "id": "KsBQgoD3LX-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/dataset_tool.py --help\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "gXIAsscwLa5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove frames\n",
        "\n",
        "Remove frames if there are any. This process overrides the picture with frames removed."
      ],
      "metadata": {
        "id": "FPXQ-z-SmXdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.spatial import distance\n",
        "\n",
        "# This python script removes pictures' frames if there are any\n",
        "\n",
        "from_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "to_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "\n",
        "\n",
        "def find_left():\n",
        "    left = 0\n",
        "    for i in range(0, w_pad):\n",
        "        r_stdev = np.std(np_img[h_pad:-h_pad, i:i + 1, 0:1])\n",
        "        g_stdev = np.std(np_img[h_pad:-h_pad, i:i + 1, 1:2])\n",
        "        b_stdev = np.std(np_img[h_pad:-h_pad, i:i + 1, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[h_pad:-h_pad, i:i + 1, 0:1])\n",
        "        g_med = np.median(np_img[h_pad:-h_pad, i:i + 1, 1:2])\n",
        "        b_med = np.median(np_img[h_pad:-h_pad, i:i + 1, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        left = left + 1\n",
        "    return left\n",
        "\n",
        "\n",
        "def find_top():\n",
        "    top = 0\n",
        "    for i in range(0, h_pad):\n",
        "        r_stdev = np.std(np_img[i:i + 1, w_pad:-w_pad, 0:1])\n",
        "        g_stdev = np.std(np_img[i:i + 1, w_pad:-w_pad, 1:2])\n",
        "        b_stdev = np.std(np_img[i:i + 1, w_pad:-w_pad, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[i:i + 1, w_pad:-w_pad, 0:1])\n",
        "        g_med = np.median(np_img[i:i + 1, w_pad:-w_pad, 1:2])\n",
        "        b_med = np.median(np_img[i:i + 1, w_pad:-w_pad, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        top = top + 1\n",
        "    return top\n",
        "\n",
        "\n",
        "def find_right(right):\n",
        "    right = w\n",
        "    for i in range(0, w_pad):\n",
        "        r_stdev = np.std(np_img[h_pad:-h_pad, w - i - 1:w - i, 0:1])\n",
        "        g_stdev = np.std(np_img[h_pad:-h_pad, w - i - 1:w - i, 1:2])\n",
        "        b_stdev = np.std(np_img[h_pad:-h_pad, w - i - 1:w - i, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[h_pad:-h_pad, w - i - 1:w - i, 0:1])\n",
        "        g_med = np.median(np_img[h_pad:-h_pad, w - i - 1:w - i, 1:2])\n",
        "        b_med = np.median(np_img[h_pad:-h_pad, w - i - 1:w - i, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        right = right - 1\n",
        "    return right\n",
        "\n",
        "\n",
        "def find_bottom(bottom):\n",
        "    for i in range(0, h_pad):\n",
        "        r_stdev = np.std(np_img[h - i - 1:h - i, w_pad:-w_pad, 0:1])\n",
        "        g_stdev = np.std(np_img[h - i - 1:h - i, w_pad:-w_pad, 1:2])\n",
        "        b_stdev = np.std(np_img[h - i - 1:h - i, w_pad:-w_pad, 2:3])\n",
        "        if r_stdev * r_stdev + g_stdev * g_stdev + b_stdev * b_stdev > thresh1:\n",
        "            break\n",
        "\n",
        "        r_med = np.median(np_img[h - i - 1:h - i, w_pad:-w_pad, 0:1])\n",
        "        g_med = np.median(np_img[h - i - 1:h - i, w_pad:-w_pad, 1:2])\n",
        "        b_med = np.median(np_img[h - i - 1:h - i, w_pad:-w_pad, 2:3])\n",
        "        dst = distance.euclidean((r_med, g_med, b_med), (r_global_med, g_global_med, b_global_med))\n",
        "        if dst < thresh2:\n",
        "            break\n",
        "\n",
        "        bottom = bottom - 1\n",
        "    return bottom\n",
        "\n",
        "\n",
        "for file in os.listdir(from_path):\n",
        "    path = os.path.join(from_path, file)\n",
        "    img = Image.open(path)\n",
        "    file_name, file_extension = os.path.splitext(path)\n",
        "    print('Removing frames for image:', file_name + file_extension)\n",
        "\n",
        "    np_img = np.asarray(img)\n",
        "    # print(\"shape = \" + str(np_img.shape))\n",
        "\n",
        "    thresh1 = 15000\n",
        "    thresh2 = 30\n",
        "    w = img.width\n",
        "    h = img.height\n",
        "    pad = 30\n",
        "    w_pad = w // pad\n",
        "    h_pad = h // pad\n",
        "\n",
        "    r_global_med = np.median(np_img[h_pad:-h_pad, w_pad:-w_pad, 0:1])\n",
        "    g_global_med = np.median(np_img[h_pad:-h_pad, w_pad:-w_pad, 1:2])\n",
        "    b_global_med = np.median(np_img[h_pad:-h_pad, w_pad:-w_pad, 2:3])\n",
        "\n",
        "    left = find_left()\n",
        "    top = find_top()\n",
        "    right = find_right(w)\n",
        "    bottom = find_bottom(h)\n",
        "\n",
        "    # print(\"left = \" + str(left) + \", top = \" + str(top) +\n",
        "      #    \", right = \" + str(right) + \", bottom = \" + str(bottom) + \"\\n\")\n",
        "\n",
        "    # img.save(to_path + file)  # save the original\n",
        "    cropped_img = img.crop((left, top, right, bottom))\n",
        "    cropped_img.save(file_name + file_extension)  # and the cropped version\n",
        "\n",
        "\n",
        "print(\"All images have been cleaned from frames!\")\n"
      ],
      "metadata": {
        "id": "SD-E7AK-mbW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resize images\n",
        "\n",
        "Resize images to 1024x1024 and override them."
      ],
      "metadata": {
        "id": "CW68PWCUqezM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "image_source_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "image_target_path = '/content/drive/MyDrive/ProjectAmbition/raw_data/'\n",
        "\n",
        "# We are using Pillow to resize all images to our desired size\n",
        "\n",
        "for filename in os.listdir(image_source_path):\n",
        "    path = os.path.join(image_source_path, filename)\n",
        "    image = Image.open(path).resize((1024, 1024), Image.ANTIALIAS)\n",
        "\n",
        "    resized_image = image.save(image_target_path + filename)\n",
        "    print(f\"{filename} image is resized...\")\n",
        "\n",
        "print(\"Resizing of images is successful!\")"
      ],
      "metadata": {
        "id": "fEiSVY8mqlci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert images\n",
        "\n",
        "Convert raw data images to dataset by using StyleGAN3's built-in dataset_tool.py"
      ],
      "metadata": {
        "id": "mSZS_v2F07l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/ProjectAmbition/stylegan3/dataset_tool.py --source /content/drive/MyDrive/ProjectAmbition/raw_data/ --dest /content/drive/MyDrive/ProjectAmbition/dataset/ --resolution=1024x1024"
      ],
      "metadata": {
        "id": "nYWi_5DSfKoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d3f8d6-3571-4307-9d9b-3ec69ae72e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 20903/20903 [1:17:28<00:00,  4.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following command can be used to clear out the newly created dataset. If something goes wrong and you need to clean up your images and rerun the above command, you should delete your partially created dataset directory."
      ],
      "metadata": {
        "id": "JfUa1rMSlvTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -R /content/drive/MyDrive/ProjectAmbition/dataset/*"
      ],
      "metadata": {
        "id": "pS0JPUa0lzoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "VIF5keq1x9MA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial training"
      ],
      "metadata": {
        "id": "Ct68q26xyA2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/train.py --help\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "txTGnCbG5V0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries. Must be installed"
      ],
      "metadata": {
        "id": "Bmjw3QwfWyWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kl1Of24-cnB",
        "outputId": "d3acbbd4-81d4-4efa-ebd7-dafb8cf761f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 11.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0\n",
        "!pip install transformers==4.8.0"
      ],
      "metadata": {
        "id": "2SCfdoIkYfbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcbb962-47d2-4b6f-ce34-97b497d9deb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0\n",
            "  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 58.4 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "Successfully installed torch-1.9.0 torchaudio-0.9.0 torchtext-0.10.0 torchvision-0.10.0\n",
            "Collecting transformers==4.8.0\n",
            "  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 13.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (3.13)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.0) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# !export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
        "\n",
        "# Modify these to suit your needs\n",
        "OUTPUT = \"/content/drive/MyDrive/ProjectAmbition/output\"\n",
        "DATA = \"/content/drive/MyDrive/ProjectAmbition/dataset\"\n",
        "# Snap: How often should the model generate samples and a .pkl file\n",
        "SNAP = 5\n",
        "# Mirrored: Should the images be mirrored left to right?\n",
        "MIRRORED = True\n",
        "\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/train.py --cfg=stylegan3-t --gpus=1 --batch=8 --gamma=32 --snap {SNAP} --outdir {OUTPUT} --data {DATA} --mirror={MIRRORED}\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "Puuif5Y7yBXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4498f318-952d-4946-ab7b-b98023e282b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9997227795604651\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 32.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/ProjectAmbition/dataset\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 20903,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 1024,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 8,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 25000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 5,\n",
            "  \"network_snapshot_ticks\": 5,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 2.5,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/ProjectAmbition/output/00005-stylegan3-t-dataset-gpus1-batch8-gamma32\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/ProjectAmbition/output/00005-stylegan3-t-dataset-gpus1-batch8-gamma32\n",
            "Number of GPUs:      1\n",
            "Batch size:          8 images\n",
            "Training duration:   25000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/ProjectAmbition/dataset\n",
            "Dataset size:        20903 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  41806\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [8, 512]             float32 \n",
            "mapping.fc1                   262656      -        [8, 512]             float32 \n",
            "mapping                       -           512      [8, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [8, 4]               float32 \n",
            "synthesis.input               262144      1545     [8, 512, 36, 36]     float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L0_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L1_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L2_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L2_52_512           2359808     37       [8, 512, 52, 52]     float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L3_52_512           2359808     25       [8, 512, 52, 52]     float32 \n",
            "synthesis.L4_84_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L4_84_512           2359808     37       [8, 512, 84, 84]     float32 \n",
            "synthesis.L5_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L5_148_512          2359808     37       [8, 512, 148, 148]   float16 \n",
            "synthesis.L6_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L6_148_512          2359808     25       [8, 512, 148, 148]   float16 \n",
            "synthesis.L7_276_323.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L7_276_323          1488707     37       [8, 323, 276, 276]   float16 \n",
            "synthesis.L8_276_203.affine   165699      -        [8, 323]             float32 \n",
            "synthesis.L8_276_203          590324      25       [8, 203, 276, 276]   float16 \n",
            "synthesis.L9_532_128.affine   104139      -        [8, 203]             float32 \n",
            "synthesis.L9_532_128          233984      37       [8, 128, 532, 532]   float16 \n",
            "synthesis.L10_1044_81.affine  65664       -        [8, 128]             float32 \n",
            "synthesis.L10_1044_81         93393       37       [8, 81, 1044, 1044]  float16 \n",
            "synthesis.L11_1044_51.affine  41553       -        [8, 81]              float32 \n",
            "synthesis.L11_1044_51         37230       25       [8, 51, 1044, 1044]  float16 \n",
            "synthesis.L12_1044_32.affine  26163       -        [8, 51]              float32 \n",
            "synthesis.L12_1044_32         14720       25       [8, 32, 1044, 1044]  float16 \n",
            "synthesis.L13_1024_32.affine  16416       -        [8, 32]              float32 \n",
            "synthesis.L13_1024_32         9248        25       [8, 32, 1024, 1024]  float16 \n",
            "synthesis.L14_1024_3.affine   16416       -        [8, 32]              float32 \n",
            "synthesis.L14_1024_3          99          1        [8, 3, 1024, 1024]   float16 \n",
            "synthesis                     -           -        [8, 3, 1024, 1024]   float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         22313167    2480     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [8, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [8, 64, 512, 512]    float16 \n",
            "b1024          -           16       [8, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [8, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [8, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [8, 128, 256, 256]   float16 \n",
            "b512           -           16       [8, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]   float16 \n",
            "b256           -           16       [8, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]     float16 \n",
            "b128           -           16       [8, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b64            -           16       [8, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b32            -           16       [8, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]       float32 \n",
            "b16            -           16       [8, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]       float32 \n",
            "b8             -           16       [8, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [8, 512]             float32 \n",
            "b4.out         513         -        [8, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 42s       sec/tick 55.6    sec/kimg 6953.40 maintenance 46.3   cpumem 4.42   gpumem 13.03  reserved 14.69  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "{\"results\": {\"fid50k_full\": 472.4932222116447}, \"metric\": \"fid50k_full\", \"total_time\": 19002.77873969078, \"total_time_str\": \"5h 16m 43s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1641703663.1589427}\n",
            "tick 1     kimg 4.0      time 6h 42m 13s   sec/tick 5018.1  sec/kimg 1254.53 maintenance 19012.8 cpumem 5.61   gpumem 12.98  reserved 14.05  augment 0.003\n",
            "tick 2     kimg 8.0      time 8h 05m 38s   sec/tick 5002.5  sec/kimg 1250.62 maintenance 2.9    cpumem 4.99   gpumem 12.98  reserved 13.93  augment 0.009\n",
            "tick 3     kimg 12.0     time 9h 29m 03s   sec/tick 5001.9  sec/kimg 1250.48 maintenance 2.9    cpumem 4.75   gpumem 13.06  reserved 13.93  augment 0.014\n",
            "tick 4     kimg 16.0     time 10h 52m 35s  sec/tick 5008.7  sec/kimg 1252.18 maintenance 2.9    cpumem 4.60   gpumem 13.02  reserved 14.43  augment 0.021\n",
            "tick 5     kimg 20.0     time 12h 18m 22s  sec/tick 5144.2  sec/kimg 1286.05 maintenance 2.9    cpumem 4.40   gpumem 13.17  reserved 14.43  augment 0.029\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 272.0643126065195}, \"metric\": \"fid50k_full\", \"total_time\": 4119.159305095673, \"total_time_str\": \"1h 08m 39s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000020.pkl\", \"timestamp\": 1641732980.2931252}\n",
            "tick 6     kimg 24.0     time 14h 50m 37s  sec/tick 5003.8  sec/kimg 1250.95 maintenance 4131.0 cpumem 6.18   gpumem 13.18  reserved 14.43  augment 0.037\n",
            "tick 7     kimg 28.0     time 16h 14m 04s  sec/tick 5004.5  sec/kimg 1251.12 maintenance 2.9    cpumem 4.41   gpumem 13.03  reserved 14.43  augment 0.044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resume training"
      ],
      "metadata": {
        "id": "y8MZ2hfhyB35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja\n",
        "!pip install torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0\n",
        "!pip install transformers==4.8.0\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "# Modify these to suit your needs\n",
        "OUTPUT = \"/content/drive/MyDrive/ProjectAmbition/output\"\n",
        "NETWORK = \"network-snapshot-000020.pkl\"\n",
        "RESUME = os.path.join(OUTPUT, \"00005-stylegan3-t-dataset-gpus1-batch8-gamma32\", NETWORK)\n",
        "DATA = \"/content/drive/MyDrive/ProjectAmbition/dataset\"\n",
        "# Snap: How often should the model generate samples and a .pkl file\n",
        "SNAP = 5\n",
        "# Mirrored: Should the images be mirrored left to right?\n",
        "MIRRORED = True\n",
        "\n",
        "\n",
        "# Build the command and run it\n",
        "cmd = f\"/usr/bin/python3 /content/drive/MyDrive/ProjectAmbition/stylegan3/train.py --cfg=stylegan3-t --gpus=1 --batch=8 --gamma=32 --snap {SNAP} --resume {RESUME} --outdir {OUTPUT} --data {DATA} --mirror={MIRRORED}\"\n",
        "!{cmd}"
      ],
      "metadata": {
        "id": "7fNrhw89yCVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ac1095-eac8-46df-ffd6-d8cdf88d4705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 41.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 14.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9997227795604651\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 32.0,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/ProjectAmbition/dataset\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 20903,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 1024,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 8,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 25000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 5,\n",
            "  \"network_snapshot_ticks\": 5,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 2.5,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/ProjectAmbition/output/00005-stylegan3-t-dataset-gpus1-batch8-gamma32/network-snapshot-000020.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/ProjectAmbition/output/00008-stylegan3-t-dataset-gpus1-batch8-gamma32\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/ProjectAmbition/output/00008-stylegan3-t-dataset-gpus1-batch8-gamma32\n",
            "Number of GPUs:      1\n",
            "Batch size:          8 images\n",
            "Training duration:   25000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/ProjectAmbition/dataset\n",
            "Dataset size:        20903 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  41806\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/ProjectAmbition/output/00005-stylegan3-t-dataset-gpus1-batch8-gamma32/network-snapshot-000020.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [8, 512]             float32 \n",
            "mapping.fc1                   262656      -        [8, 512]             float32 \n",
            "mapping                       -           512      [8, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [8, 4]               float32 \n",
            "synthesis.input               262144      1545     [8, 512, 36, 36]     float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L0_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L1_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L2_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L2_52_512           2359808     37       [8, 512, 52, 52]     float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L3_52_512           2359808     25       [8, 512, 52, 52]     float32 \n",
            "synthesis.L4_84_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L4_84_512           2359808     37       [8, 512, 84, 84]     float32 \n",
            "synthesis.L5_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L5_148_512          2359808     37       [8, 512, 148, 148]   float16 \n",
            "synthesis.L6_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L6_148_512          2359808     25       [8, 512, 148, 148]   float16 \n",
            "synthesis.L7_276_323.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L7_276_323          1488707     37       [8, 323, 276, 276]   float16 \n",
            "synthesis.L8_276_203.affine   165699      -        [8, 323]             float32 \n",
            "synthesis.L8_276_203          590324      25       [8, 203, 276, 276]   float16 \n",
            "synthesis.L9_532_128.affine   104139      -        [8, 203]             float32 \n",
            "synthesis.L9_532_128          233984      37       [8, 128, 532, 532]   float16 \n",
            "synthesis.L10_1044_81.affine  65664       -        [8, 128]             float32 \n",
            "synthesis.L10_1044_81         93393       37       [8, 81, 1044, 1044]  float16 \n",
            "synthesis.L11_1044_51.affine  41553       -        [8, 81]              float32 \n",
            "synthesis.L11_1044_51         37230       25       [8, 51, 1044, 1044]  float16 \n",
            "synthesis.L12_1044_32.affine  26163       -        [8, 51]              float32 \n",
            "synthesis.L12_1044_32         14720       25       [8, 32, 1044, 1044]  float16 \n",
            "synthesis.L13_1024_32.affine  16416       -        [8, 32]              float32 \n",
            "synthesis.L13_1024_32         9248        25       [8, 32, 1024, 1024]  float16 \n",
            "synthesis.L14_1024_3.affine   16416       -        [8, 32]              float32 \n",
            "synthesis.L14_1024_3          99          1        [8, 3, 1024, 1024]   float16 \n",
            "synthesis                     -           -        [8, 3, 1024, 1024]   float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         22313167    2480     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [8, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [8, 64, 512, 512]    float16 \n",
            "b1024          -           16       [8, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [8, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [8, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [8, 128, 256, 256]   float16 \n",
            "b512           -           16       [8, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]   float16 \n",
            "b256           -           16       [8, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]     float16 \n",
            "b128           -           16       [8, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b64            -           16       [8, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b32            -           16       [8, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]       float32 \n",
            "b16            -           16       [8, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]       float32 \n",
            "b8             -           16       [8, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [8, 512]             float32 \n",
            "b4.out         513         -        [8, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 4m 17s       sec/tick 89.5    sec/kimg 11193.17 maintenance 167.6  cpumem 6.11   gpumem 13.01  reserved 14.54  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 272.06346902406716}, \"metric\": \"fid50k_full\", \"total_time\": 16702.36370062828, \"total_time_str\": \"4h 38m 22s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1641866730.592623}\n",
            "tick 1     kimg 4.0      time 6h 58m 34s   sec/tick 8143.3  sec/kimg 2035.82 maintenance 16713.1 cpumem 6.94   gpumem 13.65  reserved 14.47  augment 0.039\n",
            "tick 2     kimg 8.0      time 9h 14m 42s   sec/tick 8165.2  sec/kimg 2041.31 maintenance 2.9    cpumem 6.34   gpumem 13.74  reserved 14.47  augment 0.077\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/training/training_loop.py\", line 278, in training_loop\n",
            "    loss.accumulate_gradients(phase=phase.name, real_img=real_img, real_c=real_c, gen_z=gen_z, gen_c=gen_c, gain=phase.interval, cur_nimg=cur_nimg)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/training/loss.py\", line 81, in accumulate_gradients\n",
            "    loss_Gmain.mean().mul(gain).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\", line 199, in apply\n",
            "    return user_fn(self, *args)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/torch_utils/ops/conv2d_gradfix.py\", line 140, in backward\n",
            "    grad_input = op.apply(grad_output, weight, None)\n",
            "  File \"/content/drive/MyDrive/ProjectAmbition/stylegan3/torch_utils/ops/conv2d_gradfix.py\", line 126, in forward\n",
            "    return torch.nn.functional.conv_transpose2d(input=input, weight=weight, bias=bias, output_padding=output_padding, **common_kwargs)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 514.00 MiB (GPU 0; 15.90 GiB total capacity; 12.72 GiB already allocated; 305.75 MiB free; 14.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate image"
      ],
      "metadata": {
        "id": "j6-C0KSpyDD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5KP0UWdqyD49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rgZqHe1eyEWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}